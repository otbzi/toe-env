#!/usr/bin/env python
# encoding: utf-8

'''SqlStore library for douban'''

from contextlib import contextmanager
from operator import itemgetter
from time import time
from datetime import datetime
from warnings import warn, catch_warnings, formatwarning
from hashlib import md5
import os
import re
import sys
import collections
import traceback
import syslog
import socket
import base64
import string

try:
    import cPickle as pickle
except:
    import pickle

import MySQLdb
from MySQLdb.constants.ER import NO_SUCH_TABLE

from douban.utils import hashdict
from douban.utils.config import read_config
from .dbconfig import DBConfig
from .table_finder import find_tables
from .consts import *

from douban.utils.imloaded import imloaded

imloaded('douban.sqlstore')

syslog.openlog('sqlstore')

try:
    CMDLINE = ' '.join(open('/proc/self/cmdline').read().split('\0')).strip()
except IOError:
    CMDLINE = ''

def _slog(event_type, sql='', tables=None):
    try:
        stack = ''.join(traceback.format_stack())
        data = {
            'event_type': event_type,
            'stack': stack,
            'sql': sql,
            'tables': tables or set(),
            'host': socket.gethostname(),
            'timestamp': time(),
        }
        _msg = base64.encodestring(pickle.dumps(data)).replace('\n', '')
        scribeclient.send('sqlstore', _msg)
    except Exception:
        pass

def _fake_slog(*args, **kwargs):
    pass

try:
    from scribeclib.client import scribeclient
    scribeclient.config(socket.gethostname(), 1463)
    slog = _slog
except:
    slog = _fake_slog

class TableMovedException(Exception):
    def __init__(self, table, from_farm, to_farm):
        self.table = table
        self.from_farm = from_farm
        self.to_farm = to_farm

    def __str__(self):
        return 'table %s moved from %s to %s' % \
                (self.table, self.from_farm, self.to_farm)

class QueryDisabledException(Exception):
    def __init__(self, sql, recover_timestamp):
        self.sql = sql
        self.recover_date = datetime.fromtimestamp(recover_timestamp)

    def __str__(self):
        msg = 'Query is temporarily disabled due to performance issue' \
              '(will be recoverd after %s): %s'
        return msg % (self.recover_date.strftime('%Y-%m-%d %H:%M:%S'), self.sql)

class InvalidMySQLDataException(Exception):
    def __init__(self, message, sql, args, kwargs):
        self.message = message
        self.sql = sql
        self.args = args
        self.kwargs = kwargs

    def __str__(self):
        return '%s: SQL:%s args:%s kwargs:%s' % (self.message,
                                                 self.sql,
                                                 self.args,
                                                 self.kwargs)

class LogCursor(object):
    '''记录所有执行的SQL'''

    def __init__(self, cursor):
        self.cursor = cursor
        self.log = []

    def execute(self, *a, **kw):
        '''提供与MySQLdb.Cursor相同的执行SQL接口'''

        stack = traceback.extract_stack(limit=6)
        time_begin = time()
        try:
            retval = self.cursor.execute(*a, **kw)
            timecost = time() - time_begin
            self.log.append((a, kw, timecost, stack[:-1]))
        except:
            stack = traceback.extract_stack(limit=5)
            self.log.append((a, kw, 0, stack))
            raise
        return retval

    def __iter__(self):
        return iter(self.cursor)

    def __getattr__(self, attr):
        return getattr(self.cursor, attr)

class WarningCursor(object):
    '''警告已经废弃的store调用接口'''

    def __init__(self, cursor):
        self.cursor = cursor

    def __getattr__(self, attr):
        warn("store.farm and store.farmr are deprecated interface, please "
                "use store.get_cursor() instead", DeprecationWarning,
                stacklevel=2)
        return getattr(self.cursor, attr)

class SqlFarm(object):
    '''单个数据库的访问接口'''

    isolation_levels = {
        'READ-UNCOMMITTED': 1,
        'READ-COMMITTED': 2,
        'REPEATABLE-READ': 3,
        'SERIALIZABLE': 4,
    }

    def __init__(self, conf=None, delete_without_where=False,
            store=None, name='', **kwargs):
        self.dbcnf = parse_config_string(conf)
        self.dbcnf.update(kwargs)
        self.host = self.dbcnf.get('host', '')
        self.name = name or '%s_farm' % self.host.split('_')[0]
        self.delete_without_where = delete_without_where
        self.cursor = None
        self.expire_time = None
        self.set_expire_time()
        self.store = store or SqlStore(db_config={})
        self.tx_isolation = ''

    def __str__(self):
        return '<SqlFarm object id:%s farm:%s host:%s>' % (id(self),
                                                           self.name,
                                                           self.host)

    __repr__ = __str__

    def connect(self, host, user, passwd, db, **kwargs):
        '''提供与MySQLdb.Cursor相同的数据库连接接口'''

        conn_params = dict(host=host, user=user,
                db=db, init_command="set names utf8",
                **kwargs)
        if passwd :
            conn_params['passwd'] = passwd

        try:
            if not getattr(MySQLdb, 'origin_connect', None):
                conn = MySQLdb.connect(**conn_params)
            else:
                conn = MySQLdb.origin_connect(**conn_params)
        except Exception, exc:
            print >> sys.stderr, \
                    "exception when connecting to database: %s %s %s: %s" \
                            % (host, user, db, exc)
            raise
        cursor = conn.cursor()
        cursor.execute('set sort_buffer_size=2000000')
        if self.dbcnf.get('disable_mysql_query_cache'):
            cursor.execute("set session query_cache_type = OFF")
        cursor.execute('select @@tx_isolation')
        r = cursor.fetchone()
        self.tx_isolation = r and r[0] or ''
        return LuzCursor(cursor, self)

    def close(self):
        '''关闭数据库连接'''

        if self.cursor:
            self.cursor.connection.close()
            self.cursor = None

    def is_expired(self):
        '''cursor是否已过期'''

        return self.expire_time < time()

    def set_expire_time(self):
        '''设置cursor过期时间'''

        self.expire_time = time() + (
                self.dbcnf.get('connection_expire_seconds')  or 3600)

    # TODO 修改所有调用ro参数的代码，删除已经废弃的ro参数
    def get_cursor(self, ro=False):
        '''取得执行SQL的cursor'''

        if self.cursor is None or self.is_expired():
            self.cursor = self.connect(**self.dbcnf)
            self.set_expire_time()

        self.cursor.clear_relocation_info()

        return self.cursor

    def start_log(self):
        '''开始保存SQL执行记录'''

        if self.cursor is None:
            self.cursor = self.connect(**self.dbcnf)
        if not isinstance(self.cursor, LogCursor):
            self.cursor = LogCursor(self.cursor)

    def stop_log(self):
        '''停止保存SQL执行记录'''

        if isinstance(self.cursor, LogCursor):
            self.cursor = self.cursor.cursor

    def get_log(self, name, log_format='text', with_traceback=False):
        '''获取已经保存的SQL执行记录'''

        def sql_log(name, logs, with_traceback):
            if not logs:
                return ''

            logs = sorted(logs, key=itemgetter(2), reverse=True)

            _logs = []
            _logs.append('%s: %d SQL statements (%s seconds):\n' % \
                    (name, len(logs), sum(x[2] for x in logs)))

            if with_traceback:
                _logs.extend(["%8.6fsec %s\n%s\n" %
                            (timecost, a, ''.join(traceback.format_list((stack))))
                               for a, _, timecost, stack in logs])
            else:
                _logs.extend(["%8.6fsec %s\n" % (timecost, a)
                               for a, _, timecost, stack in logs])
            return ''.join(_logs) + '\n'


        if not isinstance(self.cursor, LogCursor):
            return log_format == 'dict' and {} or ''

        if log_format == 'dict':
            return {name: self.cursor.log}
        else:
            return sql_log(name, self.cursor.log, with_traceback)

    def is_testing(self):
        '''是否连接的测试数据库：数据库名称以test开头'''

        db_name = self.dbcnf['db']
        return db_name.startswith('test')

    def refresh(self):
        """When REPEATABLE-READ or SERIALIZABLE transaction isolation level
        is used, a new transaction should be started by issuing 'commit' or
        'rollback' to get a fresher snapshot.
        """

        if not self.cursor:
            return False

        if self.isolation_levels.get(self.tx_isolation, 100) > \
                self.isolation_levels['READ-COMMITTED']:
            try:
                cursor = self.get_cursor()
                cursor.connection.rollback()
                return True
            except MySQLdb.OperationalError, exc:
                if 2000 <= exc.args[0] < 3000:
                    self.cursor = None
        return False


class VitessFarm(SqlFarm):
    def connect(self, host, port, db, **kwargs):
        from vtdb import vt_occ2
        try:
            conn = vt_occ2.connect('%s:%s' % (host, port), timeout=30, dbname=db) 
        except Exception, exc:
            print >> sys.stderr, \
                    "exception when connecting to database: %s %s %s: %s" \
                            % (host, port, db, exc)
            raise
        cursor = conn.cursor()
        cursor.execute('set sort_buffer_size=2000000')
        if self.dbcnf.get('disable_mysql_query_cache'):
            cursor.execute("set session query_cache_type = OFF")
        #cursor.execute('select @@tx_isolation')
        #r = cursor.fetchone()
        self.tx_isolation = '' #r and r[0] or ''
        return LuzCursor(cursor, self, is_vitess=True)


def parse_config_string(config_str):
    dummy = config_str.split(':')
    if len(dummy) == 4:
        host, db, user, passwd = dummy
        port = 3306
    elif len(dummy) == 5:
        host, port, db, user, passwd = dummy
    else:
        raise ValueError(config_str)
    return dict(host=host, port=int(port), db=db, user=user, passwd=passwd)

SQL_PATTERNS = {
    "select": re.compile(r'select\s.*?\sfrom\s+`?(?P<table>\w+)`?', re.I|re.S),
    "insert": re.compile(r'insert\s+(ignore\s+)?(into\s+)?`?(?P<table>\w+)`?', re.I),
    "update": re.compile(r'update\s+(ignore\s+)?`?(?P<table>\w+)`?\s+set', re.I),
    "replace": re.compile(r'replace\s+(into\s+)?`?(?P<table>\w+)`?', re.I),
    "delete": re.compile(r'delete\s+from\s+`?(?P<table>\w+)`?', re.I),
}

class SqlStore(object):

    def __init__(self, host='', user='', password='', db='luz_farm',
                 db_config=None, tables_map={}, created_via='UNKNOWN_APP', **kwargs):
        self._kwargs = kwargs
        if not SqlStore.is_safe(created_via):
            warn('SqlStore should be created via DAE API in async mode '
                 '(created via: %s' % created_via)
        self.db_config = db_config
        self.farms = {}
        self.tables = {}
        self.disabled_queries = {}
        self.disabled_queries_with_args = {}
        self.use_vitess = False

        # ConfigRceciver info
        self.cfgreloader = None
        self.cfgreloader_config_node = None
        self.cfgreloader_blacklist_node = None

        # Logging and migration info
        self.logging = False
        self.migrate_from = None
        self.migrate_to = None

        self.in_transaction = False
        self.modified_tables = set()
        self.modified_cursors = set()
        self.executed_queries = set()
        self.tables_map = tables_map

        if db_config is not None:
            self.parse_config(db_config)
        else:
            warn("SqlStore now has new interface, please use db_config as "
                    "paramater to create SqlStore object", DeprecationWarning)
            farm = SqlFarm(":".join([host, db, user, password]), name='', store=self)
            self.farms[db] = farm
            self.tables['*'] = farm


    def __str__(self):
        return '<SqlStore object id:%s with %s tables>' % (id(self),
                                                           len(self.tables))

    __repr__ = __str__


    @staticmethod
    def is_safe(created_via):
        created_via_dae_api = created_via == 'DAE_API'
        dae_async_mode = os.environ.get('DAE_WORKER', None) == 'async'
        if dae_async_mode and not created_via_dae_api:
            return False
        return True

    def enable_vitess(self):
        if not self.use_vitess:
            self.use_vitess = True
            self.parse_config(self.db_config)

    def parse_config(self, db_config):
        ''' db_config must be a dict
        '''

        _self_farms = {}
        _self_tables = {}
        _farms = db_config.get('farms', {})
        for name, farm_config in _farms.items():
            if self.use_vitess and 'vitess' in farm_config:
                farm = VitessFarm(farm_config['vitess'], store=self, name=name, **self._kwargs)
            else:
                farm = SqlFarm(farm_config['master'], store=self, name=name, **self._kwargs)
            _self_farms[name] = farm
            for table in farm_config['tables']:
                _self_tables[table] = farm
        if db_config and '*' not in _self_tables:
            raise MySQLdb.DatabaseError("No default farm specified")

        self.farms = _self_farms
        self.tables = _self_tables
        options = db_config.get('options', {})
        self.logging = options.get('logging', False)
        if os.getenv('DOUBAN_CORELIB_SQLSTORE_LOGGING'):
            self.logging = True
        self.show_warnings = options.get('show_warnings', False)
        if os.getenv('DOUBAN_CORELIB_SQLSTORE_SHOW_WARNINGS'):
            self.show_warnings = True
        self.treat_warning_as_error = options.get('treat_warning_as_error', False)
        if os.getenv('DOUBAN_CORELIB_SQLSTORE_TREAT_WARNING_AS_ERROR'):
            self.treat_warning_as_error = True
        from_farm = db_config.get('migration', {}).get('from', '')
        self.migrate_from = self.get_farm(from_farm, no_default=True)
        to_farm = db_config.get('migration', {}).get('to', '')
        self.migrate_to = self.get_farm(to_farm, no_default=True)

        self.cfgreloader_config_node = \
                db_config.get('cfgreloader', {}).get('config_node', None)
        self.cfgreloader_blacklist_node = \
                db_config.get('cfgreloader', {}).get('blacklist_node', None)

        if self.cfgreloader_config_node:
            try:
                if not self.cfgreloader:
                    from douban.cfgreloader import cfgreloader
                    self.cfgreloader = cfgreloader
            except Exception, exc:
                warn('Failed creating cfgrealoder: %s' % exc)

            if self.cfgreloader:
                try:
                    self.cfgreloader.register(self.cfgreloader_config_node,
                                              self.receive_conf,
                                              identity=self)
                except Exception, exc:
                    print >> sys.stderr, \
                            'Failed registering callback', self.receive_conf, \
                            'for node', self.cfgreloader_config_node, ':', exc

        if self.cfgreloader_blacklist_node:
            try:
                if not self.cfgreloader:
                    from douban.cfgreloader import cfgreloader
                    self.cfgreloader = cfgreloader
            except Exception, exc:
                warn('Failed creating cfgreloader: %s' % exc)

            if self.cfgreloader:
                try:
                    self.cfgreloader.register(self.cfgreloader_blacklist_node,
                                              self.receive_query_blacklist,
                                              identity=self)
                except Exception, exc:
                    print >> sys.stderr, \
                            'Failed registering callback', \
                            self.receive_query_blacklist, \
                            'for node', self.cfgreloader_config_node, ':', exc


    def receive_conf(self, data, version=None, mtime=None):
        ''' callback function for cfgmanager to receive lastest sqlstore config
        '''

        try:
            db_config = eval(data)
            self.parse_config(db_config)
            return True
        except Exception, exc:
            msg = 'in douban.sqlstore.receive_conf, '
            msg += 'Failed parsing config received from cfgreloader: %s'
            msg = msg % exc
            msg += ''.join(traceback.format_stack())
            return (False, msg)

    def receive_query_blacklist(self, data, version=None, mtime=None):
        ''' callback function for cfgmanager to receive lastest blacklist
        of queries
        '''

        try:
            blacklists = pickle.loads(data)
            now = time()

            # Clean up current blacklists in case of wrong checksums which
            # never match any real query
            for checksum, timestamp in self.disabled_queries.items():
                if timestamp < now:
                    try:
                        self.disabled_queries.pop(checksum)
                    except KeyError:
                        pass
            for checksum, timestamp in self.disabled_queries_with_args.items():
                if timestamp < now:
                    try:
                        self.disabled_queries_with_args.pop(checksum)
                    except KeyError:
                        pass

            # Update blacklists
            for checksum, timestamp in blacklists.get('partial').items():
                if timestamp > now:
                    self.disabled_queries[checksum] = timestamp
            for checksum, timestamp in blacklists.get('full').items():
                if timestamp > now:
                    self.disabled_queries_with_args[checksum] = timestamp

            return True
        except Exception, exc:
            msg = 'in douban.sqlstore.receive_query_blacklist, '
            msg += 'Failed parsing query blacklist received from cfgmanager: %s'
            msg = msg % exc
            msg += ''.join(traceback.format_stack())
            return (False, msg)

    def close(self):
        for farm in self.farms.values():
            farm.close()

    def get_farm(self, farm_name, no_default=False):
        farm = self.farms.get(farm_name)

        if farm is None and not no_default:
            warn("Farm %r is not configured, use default farm" % farm_name,
                    stacklevel=3)
            return self.tables['*']
        else:
            return farm

    def get_farm_by_table(self, table):
        farm = self.tables.get(table)
        if farm is None:
            farm_name = self.tables_map.get(table)
            if farm_name:
                farm = self.get_farm(farm_name)
        if farm is None:
            warn("Table %r is not configured, use default farm" % table,
                    stacklevel=3)
            return self.tables['*']
        else:
            return farm

    def _flush_get_cursor_log(self, cursor):
        if len(cursor.queries) > 1:
            syslog.syslog('get_cursor: %s' % '|'.join(cursor.queries))
        cursor.queries = []

    def _flush_accessed_tables(self, cursor):
        cursor.tables = set()


    # TODO 修改所有调用ro参数的代码，删除已经废弃的ro参数
    def get_cursor(self, ro=False, farm=None, table='*', tables=None):
        """get a cursor according to table or tables.

        Note:

          * If `tables` is given, `table` is ignored.
          * If `farm` is given, `table` and `tables` are both ignored.
        """

        not_specifying_table = False
        if farm:
            farm = self.get_farm(farm)
        elif tables:
            farms = set(self.get_farm_by_table(table) for table in tables)
            if len(farms) > 1:
                raise MySQLdb.DatabaseError("%s are not in the same farm" %
                    tables)
            farm = farms.pop()
        else:
            farm = self.get_farm_by_table(table)
            if table == '*':
                not_specifying_table = True
        cursor = farm.get_cursor()
        self._flush_get_cursor_log(cursor)
        self._flush_accessed_tables(cursor)
        if not_specifying_table:
            _file, _lineno, _module, _line = traceback.extract_stack(limit=2)[0]
            _query = '%s|%d|%s' % (_file, _lineno, _line)
            cursor.queries.append(_query)
        return cursor

    def parse_execute_sql(self, sql):
        sql = sql.lstrip()
        cmd = sql.split(' ', 1)[0].lower()
        if cmd not in SQL_PATTERNS:
            raise Exception, 'SQL command %s is not yet supported' % cmd
        match = SQL_PATTERNS[cmd].match(sql)
        if not match:
            raise Exception, sql

        tables = [t for t in find_tables(sql) if t in self.tables]
        table = match.group('table')

        if table in tables:
            tables.remove(table)

        return cmd, [table] + list(tables)

    def transaction_begin(self):
        if self.in_transaction or self.modified_cursors:
            raise Exception("another transaction has not been finished: %s" % ','.join(self.modified_tables))
        self.in_transaction = True
        self.modified_tables = set()
        self.modified_cursors = set()
        self.executed_queries = set()

    def transaction_end(self):
        if self.in_transaction:
            if len(self.modified_cursors) > 1:
                warn("the following tables in a transaction is not in same database: %s" % ','.join(self.modified_tables))
                if self.logging:
                    slog(WRITE_TABLES_IN_DIFFERENT_FARM)
            self.in_transaction = False

    def execute(self, sql, args=()):
        cmd, tables = self.parse_execute_sql(sql)
        if self.logging and len(tables) > 1:
            slog(MULTIPLE_TABLES_WITH_SINGLE_CURSOR, sql, tables)

        cursor = self.get_cursor(table=tables[0])
        self._flush_get_cursor_log(cursor)
        ret = cursor.execute(sql, args, called_from_store=True)
        if cmd == 'select':
            return cursor.fetchall()
        else:
            self.modified_cursors.add(cursor)
            self.modified_tables.update(tables)
            self.executed_queries.add(sql)
            if cmd == 'insert' and cursor.lastrowid:
                ret = cursor.lastrowid
            return ret

    def commit(self):
        self.transaction_end()
        first_error = None
        try:
            for cursor in self.modified_cursors:
                try:
                    cursor.connection.commit()
                except Exception, e:
                    if not first_error:
                        first_error = e
                    try:
                        cursor.farm.cursor = None
                    except Exception:
                        pass
            if self.logging and len(self.modified_tables) > 1:
                sqls = '\n'.join(self.executed_queries)
                slog(MULTIPLE_TABLES_IN_TRANSACTION, sqls, self.modified_tables)
        finally:
            self.modified_cursors.clear()
            self.modified_tables.clear()
            self.executed_queries.clear()
            if first_error:
                raise first_error

    def rollback(self):
        self.transaction_end()
        first_error = None
        try:
            for cursor in self.modified_cursors:
                try:
                    cursor.connection.rollback()
                except Exception, e:
                    if not first_error:
                        first_error = e
                    try:
                        cursor.farm.cursor = None
                    except Exception:
                        pass
            if self.logging and len(self.modified_tables) > 1:
                sqls = '\n'.join(self.executed_queries)
                slog(MULTIPLE_TABLES_IN_TRANSACTION, sqls, self.modified_tables)
        finally:
            self.modified_cursors.clear()
            self.modified_tables.clear()
            self.executed_queries.clear()
            if first_error:
                raise first_error

    def rollback_all(self, force=False):
        try:
            if force:
                for farm in self.farms.values():
                    try:
                        farm.get_cursor().connection.rollback()
                    except Exception:
                        try:
                            farm.cursor = None
                        except:
                            pass
            else:
                for cursor in self.modified_cursors:
                    try:
                        cursor.connection.rollback()
                    except Exception:
                        try:
                            cursor.farm.cursor = None
                        except Exception:
                            pass
        finally:
            self.modified_cursors.clear()
            self.modified_tables.clear()
            self.executed_queries.clear()

    def start_log(self):
        for farm in self.farms.values():
            farm.start_log()

    def stop_log(self):
        for farm in self.farms.values():
            farm.stop_log()

    # TODO 检查所有使用detail参数的代码，删除已经废弃的detail参数
    def get_log(self, detail=False, log_format='text', with_traceback=False):
        """Return SQL logs in two formats: text or dict
        """

        logs = [farm.get_log(name, log_format, with_traceback)
                for name, farm in self.farms.items()]

        if log_format == 'dict':
            _logs = {}
            for log in logs:
                _logs.update(log)
            return _logs
        else:
            return ' '.join(logs)

    def sync_row(self, from_farm, from_table, to_farm, to_table, **conditions):
        """sync rows of a table from one farm to another.

        Eg.
            store.sync_row('luz_farm', 'orc_farm.entry_vote',
                           'orc_farm', 'entry_vote',
                           user_id=1000001, entry_id=10013364)
        The above method call will copy the first row of entry_vote table
        on luz_farm to the corresponding table on orc_farm.

        """
        try:
            self._sync_row(from_farm, from_table, to_farm, to_table,
                    **conditions)
        except MySQLdb.IntegrityError:
            import traceback; traceback.print_exc()

    def _sync_row(self, from_farm, from_table, to_farm, to_table, **conditions):
        cols, vals = zip(*conditions.items())
        from_cursor = self.get_cursor(farm=from_farm)
        to_cursor = self.get_cursor(farm=to_farm)
        where_clause = "where " + ' and '.join([col+'=%s' for col in cols])

        # acquire lock
        from_cursor.connection.commit()
        sql = "update %s set %s %s" % (from_table,
                ",".join(["%s=%s"%(col,col) for col in cols]),
                where_clause)
        from_cursor.execute(sql, vals)

        sql = "select * from "+from_table+" " + where_clause
        from_cursor.execute(sql, vals)
        rows = from_cursor.fetchall()

        to_cursor.execute("delete from "+to_table+" " + where_clause, vals)
        to_cursor.connection.commit()
        if rows:
            sql = "insert into %s values (%s)" % (to_table,
                    ','.join(['%s'] * len(rows[0])))
            # try to avoid deadlock
            for row in rows :
                to_cursor.execute(sql, row)
                to_cursor.connection.commit()
            #to_cursor.executemany(sql, rows)
        #to_cursor.connection.commit()

        # release lock
        from_cursor.connection.rollback()

    def refresh_all(self):
        """When REPEATABLE-READ or SERIALIZABLE transaction isolation level
        is used, a new transaction should be started by issuing 'commit' or
        'rollback' to get a fresher snapshot.
        """

        count = 0
        for farm in self.farms.values():
            count += farm.refresh() and 1 or 0
        return count

    def is_testing(self):
        return any(farm.is_testing() for farm in self.farms.values())

    @contextmanager
    def manage_cursor(self, farm=None, table='*', tables=None, commit=True):
        cursor = self.get_cursor(farm=farm, table=table, tables=tables)
        try:
            yield cursor
        except:
            if commit:
                cursor.connection.rollback()
            raise
        else:
            if commit:
                cursor.connection.commit()

class LuzCursor():

    def __init__(self, cursor, farm, is_vitess=False):
        self.cursor = cursor
        self.farm = farm
        self.delete_without_where = self.farm.delete_without_where
        self._relocated_cursor = None
        self.queries = []
        self.tables = set()
        self.garbage_chars = string.whitespace + ';'
        self.is_vitess = is_vitess

    def __str__(self):
        name = 'LuzCursor' if not self.is_vitess else 'LuzCursor(vitess)'
        return '<%s object id:%s farm:%s host:%s>' % (name,
                                                      id(self),
                                                      self.farm.name,
                                                      self.farm.host)
    __repr__ = __str__

    def __getattr__(self, name):
        return getattr(self._relocated_cursor or self.cursor, name)

    def clear_relocation_info(self):
        self._relocated_cursor = None

    def execute(self, sql, *args, **kwargs):
        called_from_store = kwargs.pop('called_from_store', False)

        sql = sql.strip(self.garbage_chars)
        cmd = sql.split(' ', 1)[0].lower()
        if cmd != 'select':
            if self.is_vitess and self not in self.farm.store.modified_cursors:
                self.cursor.connection.begin()
            self.farm.store.modified_cursors.add(self)

        # Check if there are full parameterized queries to be blocked
        if self.farm.store.disabled_queries_with_args:
            if args:
                _sql = sql % self.cursor.connection.literal(*args)
            else:
                _sql = sql
            fingerprint = md5(_sql).hexdigest()
            expire_timestamp = \
                    self.farm.store.disabled_queries_with_args.get(fingerprint)
            if expire_timestamp:
                if expire_timestamp > time():
                    raise QueryDisabledException(_sql, expire_timestamp)
                else:
                    try:
                        self.farm.store.disabled_queries_with_args.pop(fingerprint)
                    except KeyError:
                        pass

        # Check if there are non-parameterized quereis to be blocked
        fingerprint = md5(sql).hexdigest()
        expire_timestamp = self.farm.store.disabled_queries.get(fingerprint)
        if expire_timestamp:
            if expire_timestamp > time():
                raise QueryDisabledException(sql, expire_timestamp)
            else:
                try:
                    self.farm.store.disabled_queries.pop(fingerprint)
                except KeyError:
                    pass

        source = os.environ.get('SQLSTORE_SOURCE') or CMDLINE
        source = source.replace('%', '%%')
        sql = sql + ' -- SRC:' + source + ' MD5:' + fingerprint

        try:
            if self.farm.store.logging and not called_from_store:
                pre_table_cnt = len(self.tables)
                _tables = [t for t in find_tables(sql) if t in
                        self.farm.store.tables]
                self.tables.update(_tables)
                if len(self.tables) > 1 and pre_table_cnt != len(self.tables):
                    slog(MULTIPLE_TABLES_WITH_SINGLE_CURSOR, sql, self.tables)

                if self.queries:
                    self.queries.append(sql)

            norm = sql.lower()
            if not self.delete_without_where and norm.startswith('delete ') \
                    and 'where' not in norm:
                raise Exception, 'delete without where is forbidden'
            if not self.delete_without_where and norm.startswith('update ') \
                    and 'where' not in norm:
                raise Exception, 'update without where is forbidden'

            self._relocated_cursor = None

            if not self.farm.store.show_warnings and \
                    not self.farm.store.treat_warning_as_error:
                return self.cursor.execute(sql, *args, **kwargs)

            with catch_warnings(record=True) as w:
                ret = self.cursor.execute(sql, *args, **kwargs)
                if w:
                    if self.farm.store.treat_warning_as_error:
                        self.cursor.connection.rollback()
                        raise InvalidMySQLDataException(w[0].message,
                                                        sql,
                                                        args,
                                                        kwargs)

                    print >> sys.stderr, '=== MySQL warnings start ==='
                    for _w in w:
                        print >> sys.stderr, formatwarning(_w.message,
                                                                    _w.category,
                                                                    _w.filename,
                                                                    _w.lineno,
                                                                    _w.line)

                    print >> sys.stderr, '-' * 40
                    print >> sys.stderr, 'SQL:', sql
                    print >> sys.stderr, 'args:', args
                    print >> sys.stderr, 'kwargs:', kwargs, '\n'

                    print >> sys.stderr, '-' * 40
                    print >> sys.stderr, ''.join(traceback.format_stack())
                    print >> sys.stderr, '=== MySQL warnings end ===\n'
                return ret
        except MySQLdb.OperationalError, exc:
            if 2000 <= exc.args[0] < 3000:
                self.farm.cursor = None
            raise
        except MySQLdb.ProgrammingError, exc:
            # 当表不存在时(ProgrammingError and errno 1146)尝试重新定位表，
            # 使表迁移更平滑

            exc_class, exception, tb = sys.exc_info()

            if exc.args[0] != NO_SUCH_TABLE:
                raise exc_class, exception, tb

            re_table = re.compile(r"Table '[^.]+\.([^']+)' doesn't exist")
            result = re_table.findall(exc.args[1])
            if not result:
                raise exc_class, exception, tb
            table = result[0]

            # 如果表未显式定义，不做重定位尝试
            if table not in self.farm.store.tables:
                raise exc_class, exception, tb

            if not self.farm.store.migrate_from or \
                self.farm.store.migrate_from is not self.farm:
                raise exc_class, exception, tb

            if not self.farm.store.migrate_to:
                raise exc_class, exception, tb

            # 修正配置，重定位表
            self.farm.store.tables[table] = self.farm.store.migrate_to
            self._relocated_cursor = self.farm.store.get_cursor(table=table)
            syslog.syslog('relocate table(PID: %d): %s, %s => %s (%s)' % (
                    os.getpid(),
                    sql,
                    self.cursor.connection.get_host_info(),
                    self._relocated_cursor.connection.get_host_info(),
                    id(self._relocated_cursor.connection)))
            for line in traceback.format_stack(limit=5):
                syslog.syslog(line)

            # 首次发现表发生移动，并且要对表做写操作时抛异常，下次get_cursor之
            # 后可以正常进行写操作
            re_select = re.compile('^\s*select\s+', re.IGNORECASE)
            if not re_select.match(sql):
                raise TableMovedException(table,
                                          self.farm.store.migrate_from.name,
                                          self.farm.store.migrate_to.name)

            return self._relocated_cursor.execute(sql, *args, **kwargs)

def replace_sqlstore_config(old, new):
    _configs = get_override_configs()
    _configs[str(old)] = str(new)
    cfg_override = ['%s=>%s' % (k, v) for (k, v) in _configs.items()]
    os.environ['SQLSTORE_CONFIG_OVERRIDE'] = ' '.join(cfg_override)
    # FIXME: http://pastebin.dapps.douban.com/show/6454/
    #if new.endswith('offline'):
    #    os.environ['DOUBAN_CORELIB_DISABLE_MC'] = '1'

def get_override_configs():
    cfg_override = os.environ.get('SQLSTORE_CONFIG_OVERRIDE', '')
    try:
        _configs = dict([i.split('=>') for i in cfg_override.split()])
    except:
        _configs = {}
    return _configs

_stores = {}
def store_from_config(config, use_cache=True, created_via='UNKNOWN_APP', **kwargs):
    if not SqlStore.is_safe(created_via):
        warn('SqlStore should be created via DAE API in async mode '
             '(created via: %s' % created_via)
    # Allow config override via environment variable
    # SQLSTORE_CONFIG_OVERRIDE="shire-online=>shire-offline ark-online=>ark-offline"
    _configs = get_override_configs()
    if isinstance(config, collections.Hashable) and config in _configs:
        config = _configs[config]

    if isinstance(config, (dict, basestring)):
        cache_key = hashdict([config, kwargs])
    else:
        # unexpected config format, make it unhashable, do not cache
        cache_key = {}

    cachable = use_cache and isinstance(cache_key, collections.Hashable)
    store = _stores.get(cache_key) if cachable else None
    if store is None:
        if isinstance(config, basestring):
            config = read_config(config,'sqlstore')
        store = SqlStore(db_config=config, created_via=created_via, **kwargs)
        if cachable:
            _stores[cache_key] = store
    store.rollback_all()
    return store

# vim: set et ts=4 sw=4 :
